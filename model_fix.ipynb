{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import expit as invlogit\n",
    "\n",
    "#import arviz as az\n",
    "#az.style.use(['default', 'arviz-doc'])\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "t_dict = {}\n",
    "\n",
    "# Create fake data -- by default everyone is treated\n",
    "n = 2000\n",
    "x = np.random.randint(1, 11, size=n) # vector of athleticism\n",
    "x = np.clip(np.random.normal(5.5, 1.5, n).astype(int), 1, 10) # normally distributed athleticism\n",
    "y0 = np.random.binomial(50, invlogit(0.2 * x - 2.5))\n",
    "y1 = np.random.binomial(50, invlogit(0.2 * x - 1.5))\n",
    "\n",
    "data = pd.DataFrame({'athleticism': x, 'y0': y0, 'y1': y1})\n",
    "\n",
    "true_effect = data.y1 - data.y0\n",
    "ate = true_effect.mean()\n",
    "\n",
    "# Treatment vectors\n",
    "all_treated = np.ones(n)\n",
    "random_treatment = np.random.binomial(1, 0.5, size=n)\n",
    "biased_treatment = np.random.binomial(1, invlogit(x - 5.5))\n",
    "\n",
    "# apply raondom treatment \n",
    "z = random_treatment\n",
    "data['y'] = np.where(z == 1, data.y1, data.y0)\n",
    "data['treatment'] = z\n",
    "treated = (data.treatment == 1) # mask\n",
    "\n",
    "print('True ATE:', ate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of treatment effect\n",
    "\n",
    "_ = plt.hist(data[treated].y - data[treated].y0, 100)\n",
    "plt.show\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Next let's estimate it using a naive model\n",
    "\n",
    "treatment = data.treatment\n",
    "y = data.y #- data[treated].y0\n",
    "\n",
    "with pm.Model() as model_normal:\n",
    "    alpha = pm.Normal(\"alpha\", mu=0, sigma=10)\n",
    "    beta = pm.Normal(\"beta\", mu=0, sigma=10)\n",
    "    sigma = pm.HalfNormal(\"sigma\", sigma=5)  \n",
    "\n",
    "    mu = alpha + beta * treatment\n",
    "    obs = pm.Normal(\"obs\", mu=mu, sigma=sigma, observed=y)\n",
    "\n",
    "    trace = pm.sample()\n",
    "\n",
    "pm.summary(trace)\n",
    "pm.plot_posterior(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_normal:\n",
    "    pm.sample_posterior_predictive(trace, extend_inferencedata=True)\n",
    "    pm.compute_log_likelihood(trace, extend_inferencedata=True)\n",
    "\n",
    "t_dict['model_normal'] = trace\n",
    "\n",
    "pm.loo(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace.posterior.beta.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model diagnostics look pretty much ok\n",
    "pm.plot_trace(trace)\n",
    "print(pm.summary(trace))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_ess(trace, kind=\"evolution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model does recover the treatment effect mean, but is actually rather horribly misspecified. What saves us is that we have a lot of data :)\n",
    "\n",
    "trace.posterior.beta.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ... and draw posterior predictive plot:\n",
    "pm.plot_ppc(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior predicxtive values (should be number of successful throws) have fractional values -- which of course does not make sense\n",
    "\n",
    "print(f'minimum number of throws: {trace.posterior_predictive.obs.values.min():.2f}')\n",
    "print(f'maximum number of throws: {trace.posterior_predictive.obs.values.max():.2f}\\n')\n",
    "print(trace.posterior_predictive.obs.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/Free throw.csv.zip').drop('Timestamp', axis=1)\n",
    "df.columns = ['age', 'gender', 'athleticism', 'y0', 'y1']\n",
    "\n",
    "z = np.random.binomial(1, 0.5, size=len(df))\n",
    "df['y'] = np.where(z == 1, df.y1, df.y0)\n",
    "df['treatment'] = z\n",
    "\n",
    "print('ATE:', df.groupby('treatment').y.mean()[1] - df.groupby('treatment').y.mean()[0])\n",
    "\n",
    "\n",
    "with pm.Model() as model_normal2:\n",
    "    alpha = pm.Normal(\"alpha\", mu=0, sigma=10)\n",
    "    beta = pm.Normal(\"beta\", mu=0, sigma=10)\n",
    "    sigma = pm.HalfNormal(\"sigma\", sigma=5)  \n",
    "\n",
    "    mu = alpha + beta * z\n",
    "    obs = pm.Normal(\"y\", mu=mu, sigma=sigma, observed=df.y)\n",
    "\n",
    "    trace = pm.sample()\n",
    "\n",
    "print(pm.summary(trace))\n",
    "pm.plot_trace(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With only 17 observations the posterior predictive plot is a horrible mess\n",
    "\n",
    "with model_normal2:\n",
    "    pm.sample_posterior_predictive(trace, extend_inferencedata=True)\n",
    "\n",
    "pm.plot_ppc(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can definitely do better.\n",
    "\n",
    "1. The first question is: **what do we actually want to model?** I.e. how should we express the ATE? Is it a difference between y1 and y0 in throws? Is it a delta of success rate?\n",
    "\n",
    "2. The next question is **what is the variable that we observe**? Is it a number of successful throws? Is it a success rate over n=50 throws?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First hacky attempt\n",
    "\n",
    "import pytensor.tensor as pt\n",
    "\n",
    "treatment = data.treatment.values\n",
    "y = data.y.values \n",
    "\n",
    "#treatment = df.treatment\n",
    "#y = df.y\n",
    "\n",
    "with pm.Model() as model_p1:\n",
    "    alpha = pm.Normal(\"alpha\", mu=15, sigma=10)\n",
    "    beta = pm.Normal(\"beta\", mu=0, sigma=20)\n",
    "    sigma = pm.HalfNormal(\"sigma\", sigma=5)  \n",
    "\n",
    "    mu = pt.math.maximum(0.001, alpha + beta * treatment)\n",
    "    obs = pm.Poisson(\"obs\", mu=mu, observed=y)\n",
    "\n",
    "    trace = pm.sample()\n",
    "\n",
    "ate = data.groupby('treatment').y.mean()[1] - data.groupby('treatment').y.mean()[0]\n",
    "print('ATE:', ate)\n",
    "print(pm.summary(trace))\n",
    "pm.plot_posterior(trace, var_names=[\"beta\"], ref_val=ate, textsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_trace(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_p1:\n",
    "    pm.sample_posterior_predictive(trace, extend_inferencedata=True)\n",
    "\n",
    "pm.plot_ppc(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_p1:\n",
    "    pm.compute_log_likelihood(trace, extend_inferencedata=True)\n",
    "\n",
    "t_dict['model_poisson1'] = trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace.posterior_predictive.obs #.plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, this can work, but let's see if we can do something different.\n",
    "\n",
    "Let's reconsider. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_shots = 50\n",
    "\n",
    "with pm.Model() as model_p2:\n",
    "    \n",
    "    # Prior for baseline ability\n",
    "    lambda_pre = pm.Gamma(\"lambda_pre\", alpha=1, beta=5) #, shape=n_players)\n",
    "    \n",
    "    # Treatment effect\n",
    "    theta = pm.LogNormal(\"theta\", mu=0, sigma=1)\n",
    "    \n",
    "    # Post-treatment lambda\n",
    "    lambda_post = pm.Deterministic(\"lambda_post\", lambda_pre * theta)\n",
    "\n",
    "    # Likelihood for pre- and post-treatment shots\n",
    "    y_pre_obs = pm.Poisson(\"y_pre_obs\", mu=lambda_pre * n_shots, observed=data.y0)\n",
    "    y_post_obs = pm.Poisson(\"y_post_obs\", mu=lambda_post * n_shots, observed=data.y1)\n",
    "    \n",
    "    trace = pm.sample()\n",
    "\n",
    "# Summary\n",
    "pm.plot_posterior(trace, var_names='theta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_p2:\n",
    "    pm.sample_posterior_predictive(trace, extend_inferencedata=True)\n",
    "\n",
    "pm.plot_ppc(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_shots = 50\n",
    "\n",
    "with pm.Model() as model_p3:\n",
    "\n",
    "    lambda_pre = pm.Gamma(\"lambda_pre\", alpha=1, beta=5) #, shape=n_players)\n",
    "        \n",
    "    # Treatment effect\n",
    "    theta = pm.LogNormal(\"theta\", mu=0, sigma=1)\n",
    "    \n",
    "    # Post-treatment lambda\n",
    "    lambda_post = pm.Deterministic(\"lambda_post\", lambda_pre * theta)\n",
    "\n",
    "    # Likelihood for post-treatment shots\n",
    "    lambda_obs = lambda_pre + theta*treatment\n",
    "    obs = pm.Poisson(\"obs\", mu=lambda_obs * n_shots, observed=data.y)\n",
    "    \n",
    "    trace = pm.sample() # add idata_kwargs={\"log_likelihood\": True} for LOO comparisons\n",
    "\n",
    "# Summary\n",
    "pm.plot_posterior(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_p3:\n",
    "    pm.sample_posterior_predictive(trace, extend_inferencedata=True)\n",
    "    pm.compute_log_likelihood(trace, extend_inferencedata=True)\n",
    "\n",
    "t_dict['model_poisson_m'] = trace\n",
    "\n",
    "pm.plot_ppc(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pre = trace.posterior_predictive[\"obs_pre\"].values  \n",
    "y_post = trace.posterior_predictive[\"obs_post\"].values  \n",
    "\n",
    "y_diff = y_post - y_pre\n",
    "\n",
    "print('Estimated ATE:', y_diff.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another try with additive model\n",
    "\n",
    "\n",
    "\n",
    "with pm.Model() as model_p4:\n",
    "    \n",
    "    # Prior for baseline ability\n",
    "    lambda_pre = pm.Uniform(\"lambda_pre\", 0, 50) #, shape=n_players)\n",
    "    \n",
    "    # Treatment effect\n",
    "    theta = pm.TruncatedNormal(\"theta\", mu=0, sigma=10, lower=-lambda_pre)\n",
    "    \n",
    "    # Post-treatment lambda\n",
    "    lambda_obs = lambda_pre + theta*treatment\n",
    "    \n",
    "    # Likelihood for pre- and post-treatment shots\n",
    "    obs = pm.Poisson(\"obs\", mu=lambda_obs * n_shots, observed=data.y)\n",
    "    \n",
    "    trace = pm.sample()\n",
    "\n",
    "# Summary\n",
    "pm.plot_posterior(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace.posterior_predictive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_p4:\n",
    "    pm.sample_posterior_predictive(trace, extend_inferencedata=True)\n",
    "    pm.compute_log_likelihood(trace, extend_inferencedata=True)\n",
    "\n",
    "pm.plot_ppc(trace)\n",
    "\n",
    "trace.posterior_predictive.obs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And one more try:\n",
    "\n",
    "with pm.Model() as model_p5:\n",
    "\n",
    "    t = pm.Data(\"t\", data.treatment)\n",
    "    \n",
    "    # Priors for baseline log-intensity (log-lambda)\n",
    "    mu = pm.Normal(\"mu\", mu=0, sigma=5)\n",
    "    \n",
    "    # Treatment effect priors\n",
    "    tau = pm.Normal(\"tau\", mu=0, sigma=5)\n",
    "    \n",
    "    # Expected log-lambda (Poisson intensity) for each individual\n",
    "    log_lambda = mu + tau * t\n",
    "    \n",
    "    # Likelihood (Poisson-distributed successes)\n",
    "    obs = pm.Poisson(\"obs\", mu=np.exp(log_lambda) * n_shots, observed=data.y)\n",
    "    \n",
    "    trace = pm.sample()\n",
    "\n",
    "\n",
    "print(pm.summary(trace))\n",
    "pm.plot_posterior(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_trace(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_p5:\n",
    "    pm.sample_posterior_predictive(trace, extend_inferencedata=True)\n",
    "\n",
    "pm.plot_ppc(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treated_mask = data.treatment.astype(bool)  \n",
    "\n",
    "obs_samples = trace.posterior_predictive.obs.values\n",
    "\n",
    "improvement_pred_treated = obs_samples[:, :, treated_mask] \n",
    "ate = improvement_pred_treated.mean() - data.y0.mean()\n",
    "\n",
    "ate "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Binomial models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = data.y0.values\n",
    "y_post = data.y1.values\n",
    "y = treatment*data.y1.values + (1-treatment)*data.y0.values\n",
    "\n",
    "n_shots = 50\n",
    "\n",
    "with pm.Model() as model_b1:\n",
    "    t = pm.Data(\"t\", treatment)\n",
    "\n",
    "    alpha = pm.Normal('alpha', mu=0, sigma=10)  \n",
    "    beta = pm.Normal('beta', mu=0, sigma=10)   \n",
    "\n",
    "    # Expected value of post-treatment performance\n",
    "    mu = alpha + beta * treatment\n",
    "\n",
    "    obs = pm.Binomial('obs', n=n_shots, p=pm.math.sigmoid(mu), observed=y)\n",
    "\n",
    "    trace = pm.sample()\n",
    "\n",
    "print(pm.summary(trace))\n",
    "pm.plot_posterior(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_b1:\n",
    "    pm.sample_posterior_predictive(trace, extend_inferencedata=True)\n",
    "    pm.compute_log_likelihood(trace, extend_inferencedata=True)\n",
    "\n",
    "t_dict['model_binomial1'] = trace\n",
    "\n",
    "pm.plot_ppc(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treated_mask = data.treatment.astype(bool)  \n",
    "\n",
    "obs_samples = trace.posterior_predictive.obs.values\n",
    "\n",
    "improvement_pred_treated = obs_samples[:, :, treated_mask] \n",
    "ate = improvement_pred_treated.mean() - data.y0.mean()\n",
    "\n",
    "ate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = {\"treatment\": [0, 1]}\n",
    "\n",
    "with pm.Model(coords=coords) as model_b2:\n",
    "    treatment_idx = pm.Data(\"treatment_idx\", data['treatment'], dims=\"obs\")\n",
    "    \n",
    "    # Priors for treatment effect\n",
    "    alpha = pm.Normal('alpha', mu=0, sigma=1, dims=\"treatment\")\n",
    "    beta = pm.Normal('beta', mu=0, sigma=1)\n",
    "    \n",
    "    # Logistic regression model for post-treatment probability\n",
    "    logit_p1 = alpha[treatment_idx] + beta\n",
    "    p1 = pm.math.sigmoid(logit_p1)\n",
    "    \n",
    "    # Likelihood for observed post-treatment counts\n",
    "    obs = pm.Binomial('obs', n=50, p=p1, observed=data['y1'])\n",
    "    \n",
    "    trace = pm.sample(nuts_sampler='nutpie')\n",
    "\n",
    "# Analyze results\n",
    "az.plot_posterior(trace, var_names=['alpha', 'beta']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_trace(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_b2:\n",
    "    pm.sample_posterior_predictive(trace, extend_inferencedata=True)\n",
    "    pm.compute_log_likelihood(trace, extend_inferencedata=True)\n",
    "\n",
    "pm.plot_ppc(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treated_mask = data.treatment.astype(bool)  \n",
    "\n",
    "obs_samples = trace.posterior_predictive.obs.values\n",
    "\n",
    "improvement_pred_treated = obs_samples[:, :, treated_mask] \n",
    "ate = improvement_pred_treated.mean() - data.y0.mean()\n",
    "\n",
    "ate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc_bart as pmb\n",
    "\n",
    "coords = {\"treatment\": data.treatment}\n",
    "\n",
    "with pm.Model(coords=coords) as model_bart:\n",
    "    X = data[['treatment']]\n",
    "    \n",
    "    # Model pre- and post-treatment probabilities\n",
    "    p = pmb.BART('p', X, data['y'] / 50)\n",
    "    \n",
    "    # Likelihood for observed counts\n",
    "    obs = pm.Binomial('obs', n=50, p=p, observed=data['y'])\n",
    "    \n",
    "    trace =  pm.sample()\n",
    "\n",
    "# Analyze results\n",
    "pm.plot_posterior(trace);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_bart:\n",
    "    pm.sample_posterior_predictive(trace, extend_inferencedata=True)\n",
    "    pm.compute_log_likelihood(trace, extend_inferencedata=True)\n",
    "\n",
    "t_dict['mode_bart'] = trace\n",
    "\n",
    "pm.plot_ppc(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treated_mask = data.treatment.astype(bool)  \n",
    "\n",
    "obs_samples = trace.posterior_predictive.obs.values\n",
    "\n",
    "improvement_pred_treated = obs_samples[:, :, treated_mask] \n",
    "ate = improvement_pred_treated.mean() - data.y0.mean()\n",
    "\n",
    "ate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model_b3:\n",
    "    theta_0 = pm.Beta('theta_0', alpha=1, beta=1)\n",
    "    theta_1 = pm.Beta('theta_1', alpha=1, beta=1)\n",
    "    \n",
    "    y_0 = pm.Binomial('y_0', n=50, p=theta_0, observed=df[df.treatment==0].y)\n",
    "    y_1 = pm.Binomial('y_1', n=50, p=theta_1, observed=df[df.treatment==1].y)\n",
    "    \n",
    "    ate = pm.Deterministic('ate', theta_1 - theta_0)\n",
    "\n",
    "    trace = pm.sample()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_b3:\n",
    "    pm.sample_posterior_predictive(trace, extend_inferencedata=True)\n",
    "    pm.compute_log_likelihood(trace, extend_inferencedata=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_ppc(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = az.compare(t_dict, var_name='obs')\n",
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_compare(comp) #, insample_dev=False);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salk",
   "language": "python",
   "name": "salk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
