{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import altair as alt\n",
    "import arviz as az\n",
    "import pymc_extras as pmx\n",
    "import pytensor.tensor as pt\n",
    "\n",
    "t_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall team stats\n",
    "stats = pd.read_csv('./data/basketball_results/team_statistics.csv').rename(columns={'Unnamed: 0': 'team'})\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Granular Match results\n",
    "results = pd.read_csv('./data/basketball_results/all_matches.csv')\n",
    "results.date_time = pd.to_datetime(results.date_time)\n",
    "results['diff'] = results.home_score - results.away_score\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of teams\n",
    "teams = list(set(results[\"home_team\"]).union(set(results[\"away_team\"])))\n",
    "n_teams = len(teams)\n",
    "\n",
    "# Encode teams as indices\n",
    "team_idx = {team: i for i, team in enumerate(teams)}\n",
    "results[\"home_idx\"] = results[\"home_team\"].map(team_idx)\n",
    "results[\"away_idx\"] = results[\"away_team\"].map(team_idx)\n",
    "\n",
    "# Add binary outcome variable\n",
    "results['home_win'] = results['home_score'] > results['away_score']\n",
    "\n",
    "results[['home_team','home_idx','home_score','away_team','away_idx','away_score','diff','home_win']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Win/loss model with team strenghts (ELO)\n",
    "with pm.Model(coords={\"teams\": teams}) as model:\n",
    "    # Latent strength for each team\n",
    "    team_strengths = pm.ZeroSumNormal(\"team_strengths\", sigma=30, dims=\"teams\")\n",
    "    \n",
    "    # Expected log-odds of home win\n",
    "    mu = (team_strengths[results[\"home_idx\"].values] \n",
    "          - team_strengths[results[\"away_idx\"].values])\n",
    "    \n",
    "    # Observed win/loss\n",
    "    pm.Bernoulli(\"score_diff_obs\", p=pm.math.sigmoid(mu), observed=results[\"home_win\"])\n",
    "    \n",
    "    # Sampling\n",
    "    trace = pm.sample(accept=0.9, draws=2000) #, nuts_sampler='nutpie')\n",
    "    pm.compute_log_likelihood(trace, extend_inferencedata=True)\n",
    "    pm.sample_posterior_predictive(trace, extend_inferencedata=True)\n",
    "\n",
    "print(pm.summary(trace))\n",
    "pm.plot_trace(trace)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior analysis\n",
    "az.plot_forest(trace, var_names=[\"team_strengths\"], combined=True, textsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ‘‡ Improve!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salk",
   "language": "python",
   "name": "salk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
