{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import altair as alt\n",
    "import arviz as az\n",
    "import pymc_extras as pmx\n",
    "import pytensor.tensor as pt\n",
    "\n",
    "t_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall team stats\n",
    "stats = pd.read_csv('./data/basketball_results/team_statistics.csv').rename(columns={'Unnamed: 0': 'team'})\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Granular Match results\n",
    "results = pd.read_csv('./data/basketball_results/all_matches.csv')\n",
    "results.date_time = pd.to_datetime(results.date_time)\n",
    "results['diff'] = results.home_score - results.away_score\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot home/away score differences over time\n",
    "\n",
    "base = alt.Chart().mark_circle().encode(\n",
    "    x=alt.X('yearmonth(date_time):T').title(None).axis(grid=False, labelAngle=270, tickCount=2, format='%m-%y'),\n",
    "    y=alt.Y('diff:Q').title('score difference').axis(grid=False).scale(domainMid=0), \n",
    "    color=alt.when(alt.datum.diff>0).then(alt.value(\"steelblue\")).otherwise(alt.value(\"red\")),\n",
    "    tooltip=[alt.Tooltip('home_team:N', title='home team:'), alt.Tooltip('away_team:N', title='away team:'), alt.Tooltip('diff:Q', title='score diff:')]\n",
    "    #facet=alt.Facet('home_team:N', columns=4).title(None)\n",
    ").properties(height=80, width=80)\n",
    "\n",
    "line = alt.Chart(pd.DataFrame({'y': [1]})).mark_rule(size=0.5, strokeDash=[2,2]).encode(y='y')\n",
    "\n",
    "home = alt.layer(base, line, data=results).facet('home_team:N', columns=5)\n",
    "\n",
    "base = alt.Chart().mark_circle().transform_calculate(\n",
    "    a_diff='0-datum.diff'\n",
    ").encode(\n",
    "    x=alt.X('yearmonth(date_time):T').title(None).axis(grid=False, labelAngle=270, tickCount=2, format='%m-%y'),\n",
    "    y=alt.Y('a_diff:Q').title('score difference').axis(grid=False).title(None).scale(domainMid=0), \n",
    "    color=alt.when(alt.datum.a_diff>0).then(alt.value(\"steelblue\")).otherwise(alt.value(\"red\")),\n",
    "    tooltip=[alt.Tooltip('home_team:N', title='home team:'), alt.Tooltip('away_team:N', title='away team:'), alt.Tooltip('diff:Q', title='score diff:')]\n",
    "    #facet=alt.Facet('home_team:N', columns=4).title(None)\n",
    ").properties(height=80, width=80)\n",
    "\n",
    "line = alt.Chart(pd.DataFrame({'y': [1]})).mark_rule(size=0.5, strokeDash=[2,2]).encode(y='y')\n",
    "\n",
    "away = alt.layer(base, line, data=results).facet('away_team:N', columns=5)\n",
    "\n",
    "(home | away).configure(font='SF Compact Rounded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of teams\n",
    "teams = list(set(results[\"home_team\"]).union(set(results[\"away_team\"])))\n",
    "n_teams = len(teams)\n",
    "\n",
    "# Encode teams as indices\n",
    "team_idx = {team: i for i, team in enumerate(teams)}\n",
    "results[\"home_idx\"] = results[\"home_team\"].map(team_idx)\n",
    "results[\"away_idx\"] = results[\"away_team\"].map(team_idx)\n",
    "\n",
    "# Add binary outcome variable\n",
    "results['home_win'] = results['home_score'] > results['away_score']\n",
    "\n",
    "results[['home_team','home_idx','home_score','away_team','away_idx','away_score','diff','home_win']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Win/loss model with team strenghts (ELO)\n",
    "with pm.Model(coords={\"teams\": teams}) as model:\n",
    "    # Latent strength for each team\n",
    "    team_strengths = pm.ZeroSumNormal(\"team_strengths\", sigma=3, dims=\"teams\")\n",
    "    \n",
    "    # Expected log-odds of home win\n",
    "    mu = (team_strengths[results[\"home_idx\"].values] \n",
    "          - team_strengths[results[\"away_idx\"].values])\n",
    "    \n",
    "    # Observed win/loss\n",
    "    pm.Bernoulli(\"score_diff_obs\", p=pm.math.sigmoid(mu), observed=results[\"home_win\"])\n",
    "    \n",
    "    # Sampling\n",
    "    trace = pm.sample(accept=0.9, draws=2000) #, nuts_sampler='nutpie')\n",
    "    pm.compute_log_likelihood(trace, extend_inferencedata=True)\n",
    "    pm.sample_posterior_predictive(trace, extend_inferencedata=True)\n",
    "\n",
    "print(pm.summary(trace))\n",
    "pm.plot_trace(trace)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior analysis\n",
    "az.plot_forest(trace, var_names=[\"team_strengths\"], combined=True, textsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ‘‡ Improve!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline score difference model with Normal likelihood\n",
    "\n",
    "with pm.Model(coords={\"teams\": teams}) as model:\n",
    "    # Latent strength for each team\n",
    "    team_strengths = pm.Normal(\"team_strengths\", mu=0, sigma=30, dims=\"teams\")\n",
    "    \n",
    "    # Expected score difference\n",
    "    mu = (team_strengths[results[\"home_idx\"].values] \n",
    "          - team_strengths[results[\"away_idx\"].values])\n",
    "    \n",
    "    # Normal likelihood\n",
    "    sigma = pm.HalfNormal(\"sigma\", sigma=30)\n",
    "    score_diff_obs = pm.Normal(\"score_diff_obs\", \n",
    "                                mu=mu, sigma=sigma, \n",
    "                                observed=results[\"diff\"].values)\n",
    "                \n",
    "    # Sampling\n",
    "    trace = pm.sample(accept=0.9, draws=2000) #, nuts_sampler='nutpie')\n",
    "    pm.compute_log_likelihood(trace, extend_inferencedata=True)\n",
    "    pm.sample_posterior_predictive(trace, extend_inferencedata=True)\n",
    "\n",
    "t_dict['normal_model'] = trace # Save the model trace for model comparison\n",
    "\n",
    "az.plot_forest(trace, var_names=[\"team_strengths\"], combined=True, textsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use SkewNormal for score difference\n",
    "\n",
    "with pm.Model(coords={\"teams\": teams}) as model:\n",
    "    # Latent strength for each team\n",
    "    team_strengths = pm.Normal(\"team_strengths\", mu=0, sigma=20, dims=\"teams\")\n",
    "    \n",
    "    # Skewness parameter for SkewNormal\n",
    "    alpha = pm.Normal(\"alpha\", mu=0, sigma=1)\n",
    "    \n",
    "    # Expected score difference\n",
    "    mu = (team_strengths[results[\"home_idx\"].values] \n",
    "          - team_strengths[results[\"away_idx\"].values])\n",
    "    \n",
    "    # SkewNormal likelihood\n",
    "    sigma = pm.HalfNormal(\"sigma\", sigma=30)\n",
    "    score_diff_obs = pm.SkewNormal(\"score_diff_obs\", \n",
    "                                    mu=mu, sigma=sigma, alpha=alpha, \n",
    "                                    observed=results[\"diff\"].values)\n",
    "    \n",
    "    # Sampling\n",
    "    trace = pm.sample(accept=0.9, draws=2000) #, nuts_sampler='nutpie')\n",
    "    pm.compute_log_likelihood(trace, extend_inferencedata=True)\n",
    "    pm.sample_posterior_predictive(trace, extend_inferencedata=True)\n",
    "\n",
    "t_dict['skewnormal_model'] = trace\n",
    "\n",
    "az.plot_forest(trace, var_names=[\"team_strengths\"], combined=True, textsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add home advantage\n",
    "with pm.Model(coords={\"teams\": teams}) as model:\n",
    "    # Latent strength for each team\n",
    "    team_strengths = pm.Normal(\"team_strengths\", mu=0, sigma=20, dims=\"teams\")\n",
    "    \n",
    "    # Home advantage parameter\n",
    "    home_advantage = pm.TruncatedNormal(\"home_advantage\", mu=1, sigma=2, lower=0, dims=\"teams\")\n",
    "\n",
    "    # Skewness parameter for SkewNormal\n",
    "    alpha = pm.Normal(\"alpha\", mu=0, sigma=1)\n",
    "    \n",
    "    # Expected score difference\n",
    "    mu = (team_strengths[results[\"home_idx\"].values] \n",
    "          - team_strengths[results[\"away_idx\"].values] \n",
    "          + home_advantage[results['home_idx'].values])\n",
    "    \n",
    "    # SkewNormal likelihood\n",
    "    sigma = pm.HalfNormal(\"sigma\", sigma=30)\n",
    "    score_diff_obs = pm.SkewNormal(\"score_diff_obs\", mu=mu, sigma=sigma, alpha=alpha, observed=results[\"diff\"].values)\n",
    "    \n",
    "    # Sampling\n",
    "    trace = pm.sample(accept=0.9, draws=2000) #, nuts_sampler='nutpie')\n",
    "    pm.compute_log_likelihood(trace, extend_inferencedata=True)\n",
    "    pm.sample_posterior_predictive(trace, extend_inferencedata=True)\n",
    "\n",
    "t_dict['skewnormal_hadv_model'] = trace\n",
    "\n",
    "az.plot_forest(trace, var_names=[\"team_strengths\"], combined=True, textsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean home court advantage: {trace.posterior.home_advantage.mean().values:.2f}\")\n",
    "pm.plot_forest(trace, var_names='home_advantage', combined=True, textsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check in: let's compare the models\n",
    "c = az.compare(t_dict)\n",
    "print(c)\n",
    "az.plot_compare(c, textsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this you will need to conda install pymc_extras\n",
    "\n",
    "from pymc_extras.distributions import Skellam\n",
    "\n",
    "# Model scores separately\n",
    "with pm.Model(coords={\"teams\": teams}) as model:\n",
    "    # Latent strength for each team\n",
    "    team_strengths = pm.Normal(\"team_strengths\", mu=60, sigma=30, dims=\"teams\")\n",
    "    \n",
    "    # Home advantage parameter\n",
    "    home_advantage = pm.TruncatedNormal(\"home_advantage\", mu=1, sigma=2, lower=0)#, dims=\"teams\")\n",
    "\n",
    "    # Poisson distribution for home and away scores\n",
    "    lambda_home = pm.math.maximum(1, team_strengths[results[\"home_idx\"].values] + home_advantage)\n",
    "    lambda_away = pm.math.maximum(1, team_strengths[results[\"away_idx\"].values])\n",
    "\n",
    "    # Observed scores\n",
    "    home_score = pm.Poisson(\"home_score\", lambda_home, observed=results[\"home_score\"])\n",
    "    away_score = pm.Poisson(\"away_score\", lambda_away, observed=results[\"away_score\"])\n",
    "\n",
    "    # Calculate score difference and save it to posterior\n",
    "    score_diff = pm.Deterministic(\"score_diff\", home_score - away_score)\n",
    "    \n",
    "    trace = pm.sample() \n",
    "\n",
    "with model:\n",
    "    # Likelihood: The score difference follows a Skellam distribution (diff of two poisson distributions)\n",
    "    # We are adding it here as a pseudo-observation to get it in posterior so we can compare it with other models\n",
    "    score_diff_obs = Skellam(\"score_diff_obs\", lambda_home, lambda_away, observed=results[\"diff\"].values)\n",
    "    pm.compute_log_likelihood(trace, extend_inferencedata=True)\n",
    "    pm.sample_posterior_predictive(trace, extend_inferencedata=True)\n",
    "    \n",
    "t_dict['poisson_model'] = trace\n",
    "\n",
    "az.plot_forest(trace, var_names=[\"team_strengths\"], combined=True, textsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc_extras.distributions import Skellam\n",
    "\n",
    "# Model scores separately\n",
    "with pm.Model(coords={\"teams\": teams}) as model:\n",
    "    # Latent strength for each team\n",
    "    team_strengths = pm.Normal(\"team_strengths\", mu=60, sigma=30, dims=\"teams\")\n",
    "\n",
    "    # Defence strength for each team, i.e. how many points they deny to the opposing team\n",
    "    team_defence = pm.HalfNormal(\"team_defence\", sigma=30, dims=\"teams\")\n",
    "    \n",
    "    # Home advantage parameter\n",
    "    home_advantage = pm.TruncatedNormal(\"home_advantage\", mu=1, sigma=2, lower=0)#, dims=\"teams\")\n",
    "    \n",
    "    # Poisson distribution for home and away scores\n",
    "    lambda_home = pm.math.maximum(1, team_strengths[results[\"home_idx\"].values] + home_advantage\n",
    "                                    - team_defence[results[\"away_idx\"].values])\n",
    "    lambda_away = pm.math.maximum(1, team_strengths[results[\"away_idx\"].values]\n",
    "                                    - team_defence[results[\"home_idx\"].values])\n",
    "\n",
    "    # Observed scores\n",
    "    pm.Poisson(\"home_score\", lambda_home, observed=results[\"home_score\"])\n",
    "    pm.Poisson(\"away_score\", lambda_away, observed=results[\"away_score\"])\n",
    "    \n",
    "    trace = pm.sample() #nuts_sampler='nutpie')\n",
    "\n",
    "with model:\n",
    "    # Likelihood: The score difference follows a Skellam distribution (diff of two poisson distributions)\n",
    "    # We are adding it here as a pseudo-observation to get it in posterior so we can compare it with other models\n",
    "    score_diff_obs = Skellam(\"score_diff_obs\", lambda_home, lambda_away, observed=results[\"diff\"].values)\n",
    "    pm.compute_log_likelihood(trace, extend_inferencedata=True)\n",
    "    pm.sample_posterior_predictive(trace, extend_inferencedata=True)\n",
    "    \n",
    "t_dict['poisson_defence_model'] = trace\n",
    "\n",
    "az.plot_forest(trace, var_names=[\"team_strengths\"], combined=True, textsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_trace(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiplicative model for Poisson\n",
    "with pm.Model(coords={\"teams\": teams}) as model:\n",
    "    # Latent strength for each team\n",
    "    team_offence = pm.Normal(\"team_offence\", mu=np.log(60), sigma=5, dims=\"teams\")\n",
    "    team_defence = pm.Normal(\"team_defence\", sigma=3, dims=\"teams\")\n",
    "    \n",
    "    # Home advantage \n",
    "    home_advantage = pm.TruncatedNormal(\"home_advantage\", mu=1, sigma=1, lower=0)#, dims=\"teams\")\n",
    "\n",
    "    # Another option for defense - as a multiplier for the other team's scoring rate\n",
    "    lambda_home = pm.math.exp(team_offence[results[\"home_idx\"].values] + home_advantage\n",
    "                                - team_defence[results[\"away_idx\"].values])\n",
    "    lambda_away = pm.math.exp(team_offence[results[\"away_idx\"].values] \n",
    "                                - team_defence[results[\"home_idx\"].values])\n",
    "\n",
    "    pm.Poisson(\"home_score\", lambda_home, observed=results[\"home_score\"])\n",
    "    pm.Poisson(\"away_score\", lambda_away, observed=results[\"away_score\"])\n",
    "    \n",
    "    trace = pm.sample(nuts_sampler='nutpie')\n",
    "\n",
    "with model:\n",
    "    # Likelihood: The score difference follows a Skellam distribution\n",
    "    score_diff_obs = Skellam(\"score_diff_obs\", lambda_home, lambda_away, observed=results[\"diff\"].values)\n",
    "    pm.compute_log_likelihood(trace, extend_inferencedata=True)\n",
    "    pm.sample_posterior_predictive(trace, extend_inferencedata=True)\n",
    "\n",
    "t_dict['poisson_mult'] = trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with matchup-specific effects\n",
    "\n",
    "# Create a separate dimension name for the opponent teams\n",
    "coords = {\"teams\": teams, \"opp_teams\": teams} \n",
    "with pm.Model(coords=coords) as model:\n",
    "    # Latent strength for each team\n",
    "    team_strengths = pm.Normal(\"team_strengths\", mu=0, sigma=20, dims=\"teams\")\n",
    "    \n",
    "    # Home advantage parameter\n",
    "    home_advantage = pm.TruncatedNormal(\"home_advantage\", mu=1, sigma=2, lower=0, dims=\"teams\")\n",
    "\n",
    "    # Skewness parameter for SkewNormal\n",
    "    alpha = pm.Normal(\"alpha\", mu=0, sigma=7)\n",
    "    \n",
    "    # Matchup effect - note the different dimension names\n",
    "    matchup_effect = pm.Normal(\"matchup_effect\", mu=0, sigma=10, dims=(\"teams\", \"opp_teams\"))\n",
    "    \n",
    "    # Expected score difference with matchup effect\n",
    "    mu = (team_strengths[results[\"home_idx\"].values] \n",
    "          - team_strengths[results[\"away_idx\"].values] \n",
    "          + home_advantage[results[\"home_idx\"].values]\n",
    "          + matchup_effect[results[\"home_idx\"].values, results[\"away_idx\"].values])\n",
    "    \n",
    "    # Likelihood\n",
    "    sigma = pm.HalfNormal(\"sigma\", sigma=10)\n",
    "    score_diff_obs = pm.SkewNormal(\"score_diff_obs\", mu=mu, sigma=sigma, alpha=alpha, observed=results[\"diff\"].values)\n",
    "\n",
    "    #w = pm.Beta(\"w\", alpha=2, beta=2)  # Mixture weight\n",
    "    #component1 = pm.SkewNormal.dist(mu=mu, sigma=sigma, alpha=alpha)\n",
    "    #component2 = pm.SkewNormal.dist(mu=mu, sigma=sigma*2, alpha=alpha)  # Wider variance component\n",
    "    #score_diff_obs = pm.Mixture(\"score_diff_obs\", w=[w, 1-w], comp_dists=[component1, component2], observed=results[\"diff\"].values)\n",
    "\n",
    "    # Sampling\n",
    "    trace = pm.sample(draws=2000, nuts_sampler='nutpie')\n",
    "    pm.compute_log_likelihood(trace, extend_inferencedata=True)\n",
    "    pm.sample_posterior_predictive(trace, extend_inferencedata=True)\n",
    "\n",
    "t_dict['interactions_model'] = trace\n",
    "\n",
    "pm.plot_trace(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now ... drumroll.. the final model comparison:\n",
    "\n",
    "comparison = az.compare(t_dict,var_name=\"score_diff_obs\")\n",
    "print(comparison)\n",
    "az.plot_compare(comparison, textsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salk",
   "language": "python",
   "name": "salk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
